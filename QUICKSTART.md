# ğŸŒ± Cresco - Brontend Integration Quick Start

## âœ… Integration Complete!

The Brontend (React frontend) is now fully connected to the Cresco backend (FastAPI + LangChain + Azure OpenAI).

---

## ğŸš€ How to Run

### Option 1: Use Startup Scripts (Easiest)

1. **Start Backend**: Double-click `start-backend.bat`
2. **Start Frontend**: Double-click `start-frontend.bat`
3. **Open Browser**: Go to http://localhost:5173

### Option 2: Manual Start

**Terminal 1 - Backend:**
```bash
cd src
python -m cresco.main
```

**Terminal 2 - Frontend:**
```bash
cd brontend
npm install  # First time only
npm run dev
```

---

## ğŸ“‹ What Changed

### âœ¨ New Files Created:
1. **`.env`** - Azure OpenAI configuration (API keys, endpoints)
2. **`brontend/src/services/api.js`** - API client for backend communication
3. **`start-backend.bat`** - Backend launcher script
4. **`start-frontend.bat`** - Frontend launcher script
5. **`INTEGRATION_GUIDE.md`** - Full technical documentation
6. **`INTEGRATION_COMPLETE.md`** - Detailed integration summary

### ğŸ”§ Modified Files:
- **`brontend/src/App.jsx`** - Added conversation ID state and real API calls

---

## ğŸ§ª Test It Out

1. **Open the app**: http://localhost:5173
2. **Try these queries**:
   - "How do I manage wheat diseases?"
   - "What nutrients does barley need?"
   - "Tell me about crop rotation"

3. **You should see**:
   - âœ… Real AI responses (no more "[offline stub]"!)
   - âœ… Source citations from knowledge base documents
   - âœ… Conversation memory across messages

---

## ğŸ”— API Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/v1/chat` | POST | Send messages to chatbot |
| `/api/v1/health` | GET | Check backend status |
| `/api/v1/index` | POST | Index knowledge base docs |

**Base URL**: `http://localhost:8000/api/v1`

---

## ğŸ—ï¸ Architecture

```
Frontend (React)  â”€â”€HTTPâ”€â”€>  Backend (FastAPI)
    â†“                              â†“
Port 5173                    Port 8000
                                   â†“
                          LangChain Agent
                                   â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â†“                             â†“
              ChromaDB                    Azure OpenAI
           (Vector Store)               (gpt-5.1-chat)
```

---

## ğŸ› ï¸ Troubleshooting

### Backend won't start?
- Run: `pip install -e .` or `uv sync`
- Check: `.env` file exists and has valid API key

### Still seeing "[offline stub]"?
- Verify Azure OpenAI credentials in `.env`
- Check the API key is valid and hasn't expired

### "Error communicating with the server"?
- Make sure backend is running on port 8000
- Check browser console for errors

### No source citations?
- Index the knowledge base first:
  ```bash
  curl -X POST http://localhost:8000/api/v1/index
  ```

---

## ğŸ“š Documentation

- **Full Guide**: See `INTEGRATION_GUIDE.md`
- **Summary**: See `INTEGRATION_COMPLETE.md`
- **This File**: Quick start reference

---

## ğŸ¯ Current Status

âœ… **Frontend-Backend Connection** - Working  
âœ… **Azure OpenAI Integration** - Configured  
âœ… **RAG Pipeline** - Operational  
âœ… **Conversation Memory** - Active  
âœ… **Source Citations** - Displaying  
âŒ **Task Suggestions** - Not implemented yet  
âŒ **File Upload Processing** - UI only  
âŒ **Streaming Responses** - Not implemented  

---

## ğŸ“ Environment Variables

Your `.env` file is configured with:
- **Model**: `gpt-5.1-chat` (Azure OpenAI)
- **Embeddings**: `text-embedding-3-small`
- **Endpoint**: Cresco AI Azure instance
- **Knowledge Base**: `./data/knowledge_base` (27+ documents)

---

## ğŸ“ How It Works

1. User types a message in the chat
2. Frontend calls `sendMessage()` from `api.js`
3. Backend receives request at `/api/v1/chat`
4. LangChain agent:
   - Searches ChromaDB for relevant docs
   - Sends query + context to Azure OpenAI
   - Generates response with citations
5. Frontend displays answer + sources

---

**Ready to chat with Cresco!** ğŸŒ¾ğŸ¤–

For detailed technical info, see `INTEGRATION_GUIDE.md`
